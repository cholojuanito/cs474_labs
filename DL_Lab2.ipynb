{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL_Lab2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ep2DPT3H32s9"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "# Lab 2: Intro to PyTorch\n",
        "\n",
        "## Deliverable\n",
        "\n",
        "For this lab, you will submit an ipython notebook via learningsuite.\n",
        "This lab will be mostly boilerplate code, but you will be required to implement a few extras.\n",
        "\n",
        "**NOTE: you almost certainly will not understand most of what's going on in this lab!\n",
        "That's ok - the point is just to get you going with pytorch.\n",
        "We'll be working on developing a deeper understanding of every part of this code\n",
        "over the course of the next two weeks.**\n",
        "\n",
        "A major goal of this lab is to help you become conversant in working through pytorch\n",
        "tutorials and documentation.\n",
        "So, you should feel free to google whatever you want and need!\n",
        "\n",
        "This notebook will have four parts:\n",
        "\n",
        "* Part 1: Your notebook should contain the boilerplate code. See below.\n",
        "\n",
        "* Part 2: Your notebook should extend the boilerplate code by adding a testing loop.\n",
        "\n",
        "* Part 3: Your notebook should extend the boilerplate code by adding a visualization of test/training performance over time.\n",
        "\n",
        "The resulting image could, for example, look like this:\n",
        "![](http://liftothers.org/dokuwiki/lib/exe/fetch.php?cache=&w=900&h=608&tok=3092fe&media=cs501r_f2018:lab2.png)\n",
        "\n",
        "* Part 4: Your notebook should contain the completed microtasks and pass all the asserts.\n",
        "\n",
        "See the assigned readings for pointers to documentation on pytorch.\n",
        "___\n",
        "\n",
        "### Grading standards:\n",
        "Your notebook will be graded on the following:\n",
        "\n",
        "* 40% Successfully followed lab video and typed in code\n",
        "* 20% Modified code to include a test/train split\n",
        "* 20% Modified code to include a visualization of train/test losses\n",
        "* 10% Tidy and legible figures, including labeled axes where appropriate\n",
        "* 10% Correct solutions to the microtasks\n",
        "___\n",
        "\n",
        "### Description\n",
        "Throughout this class, we will be using pytorch to implement our deep neural networks. \n",
        "Pytorch is a deep learning framework that handles the low-level details of \n",
        "GPU integration and automatic differentiation.\n",
        "\n",
        "The goal of this lab is to help you become familiar with pytorch. \n",
        "The four parts of the lab are outlined above.\n",
        "\n",
        "For part 1, you should watch the video below, and type in the code as it is explained to you.\n",
        "\n",
        "A more detailed outline of Part 1 is below.\n",
        "\n",
        "For part 2, you must add a validation (or testing) loop using the \n",
        "FashionMNIST dataset with train=False\n",
        "\n",
        "For part 3, you must plot the loss values.\n",
        "\n",
        "For part 4, you must complete the microtasks and pass all asserts.\n",
        "\n",
        "Optional: Demonstrate overfitting on the training data.\n",
        "\n",
        "The easiest way to do this is to limit the size of your training dataset \n",
        "so that it only returns a single batch (ie len(dataloader) == batch_size, \n",
        "and train for multiple epochs. For example,\n",
        "I set my batch size to 42, and augmented my dataloader to produce only 42 \n",
        "unique items by overwriting the len function to return 42. \n",
        "In my training loop, I performed a validation every epoch which basically corresponded \n",
        "to a validation every step.\n",
        "\n",
        "In practice, you will normally compute your validation loss every n steps, \n",
        "rather than at the end of every epoch. This is because some epochs can take hours, \n",
        "or even days and you donâ€™t often want to wait that long to see your results.\n",
        "\n",
        "Testing your algorithm by using a single batch and training until overfitting \n",
        "is a great way of making sure that your model and optimizer are working the way they should!\n",
        "\n",
        "___\n",
        "\n",
        "### Part 0\n",
        "[Watch Tutorial Video here](https://www.youtube.com/watch?v=E76hLX9WCLE)\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Watch video\n",
        "___\n",
        "\n",
        "### Part 1\n",
        "Your notebook should contain the boilerplate code. See below.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Replicate boilerplate from the video\n",
        "___\n",
        "\n",
        "### Part 2\n",
        "Your notebook should extend the boilerplate code by adding a testing loop.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Add a testing (validation) loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QClXc9i7VRyA",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b3480da1-fdd4-49ff-ac54-880d5017e1c2"
      },
      "source": [
        "!pip3 install torch \n",
        "!pip3 install torchvision\n",
        "!pip3 install tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchvision) (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OU80yuvqVXwk",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        " \n",
        "assert torch.cuda.is_available() # You need to request a GPU from Runtime > Change Runtime Type\n",
        "\n",
        "# Define classes that extend PyTorch classes\n",
        "# Network class\n",
        "class LinearNetwork(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(LinearNetwork, self).__init__()\n",
        "        x, y = dataset[0]\n",
        "        print(y, type(y))\n",
        "        c, h, w = x.size() # channel, height, width of image\n",
        "        out = 10\n",
        "        layer1_dim = 1000\n",
        "\n",
        "        self.net = nn.Sequential(nn.Linear(c * h * w, layer1_dim),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(layer1_dim, out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        n, c, h, w = x.size() # n = batch size\n",
        "        flattened = x.view(n, c * h * w)\n",
        "        return self.net(flattened)\n",
        "\n",
        "# Dataset class\n",
        "class FashionMNISTProcessedDataset(Dataset):\n",
        "    def __init__(self, root, train=True):\n",
        "        self.data = datasets.FashionMNIST(root, \n",
        "                                          train=train, \n",
        "                                          transform=transforms.ToTensor(),\n",
        "                                          download=True)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.data[idx]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgAkNlzDJaOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the train and validation sets\n",
        "train_dataset = FashionMNISTProcessedDataset('/tmp/fashionmnist', train=True)\n",
        "val_dataset = FashionMNISTProcessedDataset('/tmp/fashionmnist', train=False)\n",
        "\n",
        "# Instantiate your data loaders\n",
        "train_loader = DataLoader(train_dataset, # You can change the way batches are shuffled here\n",
        "                          batch_size=42, # Multiple threads\n",
        "                          pin_memory=True) # Speed improvement param, use same block of GPU memory\n",
        "val_loader = DataLoader(val_dataset, batch_size=42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRJSD5LiJwSY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9dd5206-f6ed-4237-860b-9f33cfc673bf"
      },
      "source": [
        "# Instantiate your model\n",
        "model = LinearNetwork(train_dataset)\n",
        "model = model.cuda() # Move to GPU memory\n",
        "\n",
        "# Instantiate loss and optimizer functions\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-4)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 <class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzG6t-3NJdW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18b34824-b401-43a1-e5a9-30b391f7638c"
      },
      "source": [
        "# Training and validation loops\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "num_epochs = 200\n",
        "\n",
        "loop = tqdm(total=len(train_loader) * num_epochs, position=0) # Gives an idea of how long training will take\n",
        "\n",
        "cntr = 0\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    batch = 0\n",
        "    for x, y_truth in train_loader:\n",
        "        x, y_truth = x.cuda(non_blocking=True), y_truth.cuda(non_blocking=True) # non_blocking is speed up (async)\n",
        "        \n",
        "        optimizer.zero_grad() # Set gradient to zero\n",
        "\n",
        "        y_hat = model(x)\n",
        "        loss = loss_func(y_hat, y_truth) # Both params need to be floats\n",
        "        \n",
        "        # Check the validation for first 25 epochs of first batch\n",
        "        if epoch % 25 == 0 and batch == 0:\n",
        "            train_losses.append(loss)\n",
        "\n",
        "            val_loss_list = []\n",
        "            for val_x, val_y in val_loader:\n",
        "                 val_x, val_y = val_x.cuda(non_blocking=True), val_y.cuda(non_blocking=True)\n",
        "                 val_y_hat = model(val_x)\n",
        "                 val_loss_list.append(loss_func(val_y_hat, val_y))\n",
        "\n",
        "            val_losses.append(sum(val_loss_list) / float(len(val_loss_list)))\n",
        "\n",
        "            cntr += 1\n",
        "\n",
        "        loop.set_description('loss: {:.4f}'.format(loss.item()))\n",
        "        loop.update(1)\n",
        "\n",
        "        loss.backward() # Compute gradient, for weight with respect to loss\n",
        "        optimizer.step() # Take step in the direction of the negative gradient\n",
        "        batch += 1\n",
        "\n",
        "loop.close()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.5017: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 285800/285800 [29:06<00:00, 163.61it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_IZmHOvirnFn"
      },
      "source": [
        "\n",
        "___\n",
        "\n",
        "### Part 3\n",
        "Your notebook should extend the boilerplate code by adding a visualization of test/training\n",
        "performance over time. Use matplotlib.pyplot\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "* Add a visualization of test/train performance (i.e. loss) over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YqYrbI5-WHb3",
        "pycharm": {
          "is_executing": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8578c26b-8c92-40c0-d800-4cc422eba232"
      },
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(range(len(train_losses)), train_losses, label=\"Train Loss\")\n",
        "ax.plot(range(len(val_losses)), val_losses, label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0wW4QNYG4LE2"
      },
      "source": [
        "\n",
        "___\n",
        "\n",
        "### Part 4\n",
        "Complete the following microtasks to learn some important Pytorch skills. \n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Complete microtasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A9aHouhQ6cou",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8031e9b0-23f6-47c8-a82b-92d16c50b007"
      },
      "source": [
        "# Tensors are the the lifeblood of Pytorch. \n",
        "# Construct a 5x3 tensor, 'a', of zeros and of dtype long\n",
        "a = torch.empty(5,3, dtype=torch.long)\n",
        "print(a)\n",
        "print(a.size())\n",
        "assert a.size() == torch.Size([5, 3])\n",
        "assert type(a[0][0].item()) is int"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  3105572992, 206158430258, 206158430253],\n",
            "        [193273528377, 214748364849, 210453397588],\n",
            "        [249108103223, 210453397557, 219043332154],\n",
            "        [197568495672, 231928234035, 219043332151],\n",
            "        [231928234033, 450971566170, 433791696995]])\n",
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6rfOY4HqYDTP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8626750a-ec40-4ec3-fa8c-c5a6e5175680"
      },
      "source": [
        "# Many of your bugs will come from incorrect tensor dimensions. \n",
        "# Pytorch has several built-in functions to give you the control need. \n",
        "# Using only the .unsqueeze() function, turn 'a' into a 5x1x3 tensor. Hint: use the dim= argument\n",
        "a = a.unsqueeze(dim=1)\n",
        "print(a.shape)\n",
        "assert a.shape == torch.Size([5, 1, 3])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zY1SJ95Ekokk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de6a8d26-e607-4431-fcd6-f75ae8fa657d"
      },
      "source": [
        "# Each dimension means something different. \n",
        "# You can change the order of your dimensions without losing information. \n",
        "# Reshape 'a' into a 5x3x1 tensor, using the .view() function\n",
        "a = a.view(5,3,1)\n",
        "print(a.shape)\n",
        "assert a.shape == torch.Size([5, 3, 1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_0Q_1vDtmaKW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11c3309a-d027-4d60-f728-5a47f443df6b"
      },
      "source": [
        "# Dimensions of size 1 can sometimes be necessary for shape matching.\n",
        "# However, they can be removed without losing information. \n",
        "# Squeeze 'a' to remove dimensions of 1\n",
        "a = a.squeeze()\n",
        "print(a.shape)\n",
        "assert a.size() == torch.Size([5, 3])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5miM1dYxnmSY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8b9fd2d-1cfa-4f20-cc3e-9351e49c3bfe"
      },
      "source": [
        "# You can turn any tensor into a tensor of a single dimension. \n",
        "# Flatten 'a' to a single dimension\n",
        "a = a.flatten()\n",
        "print(a.size())\n",
        "assert  a.size() == torch.Size([15]) "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oxX1Ybcc7gDW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "513cf8ff-1736-4afd-db71-1b463ac5a95e"
      },
      "source": [
        "# It's easy to integrate other common python data structures. \n",
        "# Initialize a tensor, 'b', from a list\n",
        "my_list = [1,2,3,4,5]\n",
        "b = torch.tensor(my_list)\n",
        "print(b)\n",
        "assert b.size() == torch.Size([5])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3, 4, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4XpqRqfG9DTr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "10808934-6347-4afb-fae4-fcaddd91344b"
      },
      "source": [
        "# GPUs will allow tensor operations to run much faster. \n",
        "# Assign 'a' and 'b' to run on GPU\n",
        "gpu_device = torch.device(\"cuda\")\n",
        "a = a.to(device=gpu_device)\n",
        "b = b.to(device=gpu_device)\n",
        "print(a, b)\n",
        "assert a.is_cuda and b.is_cuda"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  3105572992, 206158430258, 206158430253, 193273528377, 214748364849,\n",
            "        210453397588, 249108103223, 210453397557, 219043332154, 197568495672,\n",
            "        231928234035, 219043332151, 231928234033, 450971566170, 433791696995],\n",
            "       device='cuda:0') tensor([1, 2, 3, 4, 5], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FPD6NUDf7915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9d64bf13-3f22-465f-ffb4-541952f4fedc"
      },
      "source": [
        "# You might not always have access to a GPU\n",
        "# Assign 'a' and 'b' to run on CPU\n",
        "cpu_device = torch.device(\"cpu\")\n",
        "a = a.to(device=cpu_device)\n",
        "b = b.to(device=cpu_device)\n",
        "print(a, b)\n",
        "assert not a.is_cuda and not b.is_cuda"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  3105572992, 206158430258, 206158430253, 193273528377, 214748364849,\n",
            "        210453397588, 249108103223, 210453397557, 219043332154, 197568495672,\n",
            "        231928234035, 219043332151, 231928234033, 450971566170, 433791696995]) tensor([1, 2, 3, 4, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1GMvFc2c9P_i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9afe7a3-635a-4488-864f-18c28cdeec40"
      },
      "source": [
        "# You will often want to convert tensors to numpy arrays to interact with other python libraries\n",
        "# Convert 'a' to a numpy array 'c'\n",
        "c = a.numpy()\n",
        "print(type(c))\n",
        "assert type(c) == np.ndarray"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EVFr_ZNgBMHL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d412dc4b-1ee6-4bfa-82de-90e38fb0d4dc"
      },
      "source": [
        "# To get your data back into Pytorch\n",
        "# Convert 'c' to tensor 'd'\n",
        "d = torch.from_numpy(c,)\n",
        "print(d.type())\n",
        "assert torch.is_tensor(d)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.LongTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KElhnviDhIPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}