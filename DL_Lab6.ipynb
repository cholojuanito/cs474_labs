{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNBPF2Z6I9T9"
      },
      "source": [
        "<a \n",
        "href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab6.ipynb\"\n",
        "  target=\"_parent\">\n",
        "  <img\n",
        "    src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
        "    alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cksgAH12XRjV"
      },
      "source": [
        "# Lab 6: Sequence-to-sequence models\n",
        "\n",
        "### Description:\n",
        "For this lab, you will code up the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original.\n",
        "\n",
        "This lab will help you develop several new skills, as well as understand some best practices needed for building large models. In addition, we'll be able to create networks that generate neat text!\n",
        "\n",
        "### Deliverable:\n",
        "- Fill in the code for the RNN (using PyTorch's built-in GRU).\n",
        "- Fill in the training loop\n",
        "- Fill in the evaluation loop. In this loop, rather than using a validation set, you will sample text from the RNN.\n",
        "- Implement your own GRU cell.\n",
        "- Train your RNN on a new domain of text (Star Wars, political speeches, etc. - have fun!)\n",
        "\n",
        "### Grading Standards:\n",
        "- 20% Implementation the RNN\n",
        "- 20% Implementation training loop\n",
        "- 20% Implementation of evaluation loop\n",
        "- 20% Implementation of your own GRU cell\n",
        "- 20% Training of your RNN on a domain of your choice\n",
        "\n",
        "### Tips:\n",
        "- Read through all the helper functions, run them, and make sure you understand what they are doing\n",
        "- At each stage, ask yourself: What should the dimensions of this tensor be? Should its data type be float or int? (int is called `long` in PyTorch)\n",
        "- Don't apply a softmax inside the RNN if you are using an nn.CrossEntropyLoss (this module already applies a softmax to its input).\n",
        "\n",
        "### Example Output:\n",
        "An example of my final samples are shown below (more detail in the\n",
        "final section of this writeup), after 150 passes through the data.\n",
        "Please generate about 15 samples for each dataset.\n",
        "\n",
        "<code>\n",
        "And ifte thin forgision forward thene over up to a fear not your\n",
        "And freitions, which is great God. Behold these are the loss sub\n",
        "And ache with the Lord hath bloes, which was done to the holy Gr\n",
        "And appeicis arm vinimonahites strong in name, to doth piseling \n",
        "And miniquithers these words, he commanded order not; neither sa\n",
        "And min for many would happine even to the earth, to said unto m\n",
        "And mie first be traditions? Behold, you, because it was a sound\n",
        "And from tike ended the Lamanites had administered, and I say bi\n",
        "</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2i_QpSsWG4c"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 0: Readings, data loading, and high level training\n",
        "\n",
        "---\n",
        "\n",
        "There is a tutorial here that will help build out scaffolding code, and get an understanding of using sequences in pytorch.\n",
        "\n",
        "* Read the following\n",
        "\n",
        "> * [Pytorch sequence-to-sequence tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) (Take note that you will not be implementing the encoder part of this tutorial.)\n",
        "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztVzlgs-3qNQ"
      },
      "source": [
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "! tar -xzf text_files.tar.gz\n",
        "! pip install unidecode\n",
        "#! pip install torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sCcq74r__bd"
      },
      "source": [
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pdb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7bdZWxvJrsx",
        "outputId": "0b4a2923-c9e9-4fd8-9015-c6918d3affb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "all_characters = \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZñáéíóúüÁÉÍÓÚÜÑ¡!\\\"#$%&'()*+,-./:;«<=>»¿?@[\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c\"\n",
        "n_characters = len(all_characters)\n",
        "\n",
        "file_name = './text_files/don-quijote-espanol.txt'\n",
        "\n",
        "file = unidecode.unidecode(open(file_name, 'r', encoding='utf8').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len = 2098300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBgvV_vd02DC",
        "outputId": "65162feb-6919-48a4-cb29-31e437e30e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "all_characters"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZñáéíóúüÁÉÍÓÚÜÑ¡!\"#$%&\\'()*+,-./:;«<=>»¿?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxBeKeNjJ0NQ"
      },
      "source": [
        "chunk_len = 200\n",
        " \n",
        "def random_chunk():\n",
        "  start_index = random.randint(0, file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return file[start_index:end_index]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On0_WitWJ99e"
      },
      "source": [
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "  return tensor\n",
        "\n",
        "print(char_tensor('abcDEFñáíó¡»'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYJPTLcaYmfI"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: Creating your own GRU cell \n",
        "\n",
        "**(Come back to this later - its defined here so that the GRU will be defined before it is used)**\n",
        "\n",
        "---\n",
        "\n",
        "The cell that you used in Part 1 was a pre-defined Pytorch layer. Now, write your own GRU class using the same parameters as the built-in Pytorch class does.\n",
        "\n",
        "Please try not to look at the GRU cell definition. The answer is right there in the code, and in theory, you could just cut-and-paste it. This bit is on your honor!\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "* Create a custom GRU cell\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavAv50ZKQ-F"
      },
      "source": [
        "class GRUCell(nn.Module):\n",
        "    # Output and hidden size are synonymous\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(GRUCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "        self.W_r = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.W_z = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.W_n = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "\n",
        "    # input comes from previous layer, prev_hidden comes from previous GRU in time\n",
        "    def forward(self, input, prev_hidden):\n",
        "        # Each layer does the following:\n",
        "        # r_t = sigmoid(W_ir*x_t + b_ir . W_hr*h_(t-1) + b_hr)\n",
        "        # z_t = sigmoid(W_iz*x_t + b_iz . W_hz*h_(t-1) + b_hz)\n",
        "        # n_t = tanh(W_in*x_t + b_in . r_t**(W_hn*h_(t-1) + b_hn))\n",
        "        # h_(t) = (1 - z_t)**n_t + z_t**h_(t-1)\n",
        "        # Where ** is hadamard product (not matrix multiplication, but elementwise multiplication)\n",
        "\n",
        "        update_input = torch.cat((input, prev_hidden), dim=2)\n",
        "        update_gate = self.sigmoid(self.W_z(update_input))\n",
        "\n",
        "        reset_input = update_input.clone()\n",
        "        reset_gate = self.sigmoid(self.W_r(reset_input))\n",
        "\n",
        "        curr_mem_input = torch.cat(((reset_gate * prev_hidden), input), dim=2)\n",
        "        curr_memory = self.tanh(self.W_n(curr_mem_input))\n",
        "\n",
        "        final_memory = ((1 - update_gate) * curr_memory) + (update_gate * prev_hidden)\n",
        "\n",
        "        # Produce two verisons of this because it will be used in two places\n",
        "        return final_memory, final_memory\n",
        "    \n",
        "\n",
        "\n",
        "class MyGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(MyGRU, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.gru_cells = nn.ModuleList()\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            # First gru cell takes input_size the rest are hidden_size\n",
        "            gru_input_size = self.input_size if i == 0 else hidden_size\n",
        "            self.gru_cells.append(GRUCell(gru_input_size, hidden_size))\n",
        "  \n",
        "    def forward(self, inputs, hidden):\n",
        "        # Use first gru cell to initialize hidden_layers\n",
        "        outputs, hidden_layers = self.gru_cells[0](inputs, hidden[0:1])\n",
        "        for i, cell in enumerate(self.gru_cells):\n",
        "            outputs, hidden_layer = cell(outputs, hidden[i:i+1])\n",
        "            hidden_layers = torch.cat((hidden_layers, hidden_layer), dim=0)\n",
        "\n",
        "        return outputs, hidden_layers\n",
        "  \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtXdX-B_WiAY"
      },
      "source": [
        "---\n",
        "\n",
        "##  Part 1: Building a sequence to sequence model\n",
        "\n",
        "---\n",
        "\n",
        "Great! We have the data in a useable form. We can switch out which text file we are reading from, and trying to simulate.\n",
        "\n",
        "We now want to build out an RNN model, in this section, we will use all built in Pytorch pieces when building our RNN class.\n",
        "\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "* Create an RNN class that extends from nn.Module.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6tNdEnzWj5F"
      },
      "source": [
        "class MyRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(MyRNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = n_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(self.input_size, self.hidden_size)\n",
        "        self.gru = MyGRU(self.hidden_size, self.hidden_size, num_layers=self.num_layers)\n",
        "        self.to_out_size = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        output = torch.Tensor([])\n",
        "        #for i in range(len(input_seq)):\n",
        "        output = self.embedding(input_seq).view(1, 1, -1)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = F.relu(self.to_out_size(output))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(self.num_layers, 1, self.hidden_size)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrhXghEPKD-5"
      },
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpiGObbBX0Mr"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "We now want to be able to train our network, and sample text after training.\n",
        "\n",
        "This function outlines how training a sequence style network goes. \n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "* Fill in the pieces.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ALC3Pf8Kbsi"
      },
      "source": [
        "def train(inp, target, model, loss_func, optimizer):\n",
        "    ## initialize hidden layers, set up gradient and loss \n",
        "    optimizer.zero_grad()\n",
        "    hidden = decoder.init_hidden()\n",
        "    loss = 0\n",
        "\n",
        "    for i in range(len(inp)):\n",
        "        out_distribution, hidden = model(inp[i], hidden)\n",
        "        out_distribution = out_distribution.squeeze(0)\n",
        "        loss += loss_func(out_distribution, target[i].view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item() / len(inp)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN06NUu3YRlz"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 3: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "You can at this time, if you choose, also write out your train loop boilerplate that samples random sequences and trains your RNN. This will be helpful to have working before writing your own GRU class.\n",
        "\n",
        "If you are finished training, or during training, and you want to sample from the network you may consider using the following function. If your RNN model is instantiated as `decoder`then this will probabilistically sample a sequence of length `predict_len`\n",
        "\n",
        "**TODO:**\n",
        "* Fill out the evaluate function to generate text frome a primed string\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-bp-OZ1KjNh"
      },
      "source": [
        "def sample_outputs(output, temperature):\n",
        "    \"\"\"Takes in a vector of unnormalized probability weights and samples a character from the distribution\"\"\"\n",
        "    return torch.multinomial(torch.exp(output / temperature), 1)\n",
        "\n",
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "    ## initialize hidden state, initialize other useful variables\n",
        "    ## take output from decoder()\n",
        "    with torch.no_grad():\n",
        "        prime_input = char_tensor(prime_str)\n",
        "        hidden = decoder.init_hidden()\n",
        "        for p in range(len(prime_str) - 1):\n",
        "            _, hidden = decoder(prime_input[p], hidden)\n",
        "\n",
        "        inp = prime_input[-1]\n",
        "        for i in range(predict_len):\n",
        "            decoded_out, hidden = decoder(inp, hidden)\n",
        "            char_picked = all_characters[sample_outputs(decoded_out.view(-1), temperature)]\n",
        "            inp = char_tensor(char_picked)\n",
        "            prime_str += char_picked\n",
        "\n",
        "    return prime_str\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du4AGA8PcFEW"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: (Create a GRU cell, requirements above)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFS2bpHSZEU6"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Part 5: Run it and generate some text!\n",
        "\n",
        "---\n",
        "\n",
        "Assuming everything has gone well, you should be able to run the main function in the scaffold code, using either your custom GRU cell or the built in layer, and see output something like this. I trained on the “lotr.txt” dataset, using chunk_length=200, hidden_size=100 for 2000 epochs gave.\n",
        "\n",
        "**TODO:** \n",
        "\n",
        "**DONE:**\n",
        "\n",
        "* Create some cool output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nXFeCmdKodw"
      },
      "source": [
        "import time\n",
        "n_epochs = 2000\n",
        "print_every = 100\n",
        "plot_every = 100\n",
        "hidden_size = 200\n",
        "n_layers = 3\n",
        "lr = 0.001\n",
        "device = \"cuda\"\n",
        " \n",
        "decoder = MyRNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKfozqw-6eqb",
        "outputId": "3f0be2f1-52b4-4974-c366-c58433f15c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  loss_ = train(*random_training_set(), decoder, criterion, decoder_optimizer)\n",
        "\n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "      print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "      print(evaluate('qu', 100), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      all_losses.append(loss_avg / plot_every)\n",
        "      loss_avg = 0"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[103.78167486190796 (100 5%) 3.4747]\n",
            "quEtae    \n",
            "at,u \n",
            "%d\n",
            "  undna8rú¡d eeedl e lescr de Sesn P  an eetda ,acd t D daar a\\ saupe8atsycreí\n",
            "nre \n",
            "\n",
            "[207.23796129226685 (200 10%) 3.2122]\n",
            "qussnsaarl a, e oeVassdansu or oaree ur  us na  uoto ts\n",
            "ta noectcaselle osnt oatcaa ooaaanñosons )aors \n",
            "\n",
            "[311.2625608444214 (300 15%) 3.0495]\n",
            "quqes e cuu on  encoral#e Lorda da\n",
            "GusSas a  er en an~*ce el $: a oca nunloste a  on en e uanaton a oo \n",
            "\n",
            "[416.0506956577301 (400 20%) 2.4683]\n",
            "qua daesdade e li viea val o, a do on agidudon ;%|A>s. -7ada ma da as asode que (sa, \u000buntiar l los til \n",
            "\n",
            "[520.4615526199341 (500 25%) 2.3255]\n",
            "uego de can es galte le mo sino  \n",
            "\n",
            "[624.2953042984009 (600 30%) 2.1251]\n",
            "que, menes aquento en carco de de un cueltra cderque mo dica, venarar de cogo \n",
            "secrerle cescirciordito \n",
            "\n",
            "[728.1213171482086 (700 35%) 2.0435]\n",
            "que en na un 4u% clamado los cuacio se la viee de uscilcioso el ton tos ar que de de tia de en me 8l s \n",
            "\n",
            "[831.4449982643127 (800 40%) 2.0168]\n",
            "que te cierlo se los neces, \u000buije de la suncia a\n",
            "la caule vieros recaldia cora mi GuenDa,\n",
            "se le mas ca \n",
            "\n",
            "[935.3102531433105 (900 45%) 1.9646]\n",
            "quero moliente,\n",
            "Úon en Isbresiento lumera de el de man recontendos\n",
            "de sus cento\n",
            "a^lo, seno desde des]o \n",
            "\n",
            "[1040.3806729316711 (1000 50%) 1.8378]\n",
            "que se paraze de su irmimando lo don de su jumto de ca\fsamino de noceda 9 2acada seno la pusento que c \n",
            "\n",
            "[1143.7213852405548 (1100 55%) 1.7483]\n",
            "que se contan las camo a los lejas, que es entendemirea, que el cuecto mi de\n",
            "ser tampar cuen de\n",
            "los or \n",
            "\n",
            "[1243.5094599723816 (1200 60%) 1.9104]\n",
            "que a si le de se mas cardares se daraxperan de la en toda maner a otro el se 8nigo el mas pada ha )mo \n",
            "\n",
            "[1339.9787242412567 (1300 65%) 1.6248]\n",
            "que respondio camo ripierso que no\n",
            "se lo es es, a decir con que tiento a vala esto su amrimo tu de mon \n",
            "\n",
            "[1431.19890999794 (1400 70%) 1.6570]\n",
            "quedo de ciente de arginar si criado, y mas caso la mercimiendos norsi de contadore, que en ul pena qu \n",
            "\n",
            "[1519.3254134654999 (1500 75%) 1.7993]\n",
            "que pala'cias\n",
            "no |ejan vejo antos estas decer en las entrata mas Úedersuaza, y que en me don Quijote-  \n",
            "\n",
            "[1611.7181794643402 (1600 80%) 1.6700]\n",
            "que los rompos Sancho, cordoca deste no tengo a vuestro al mucho a los hasta a moda estas por lo volig \n",
            "\n",
            "[1704.1171338558197 (1700 85%) 1.7793]\n",
            "que me don Quijote de aHacho, que ponder salo con castivo de su hecho de tun anagua de hacea todas que \n",
            "\n",
            "[1792.5934255123138 (1800 90%) 1.7440]\n",
            "que no hay cristidor a parece, toda a ya la amigo don Quijote entra merced, si mundas es como salo siQ \n",
            "\n",
            "[1879.8797795772552 (1900 95%) 1.7286]\n",
            "quien muchas tantas que se\n",
            "dando a sus entrada la Buen de valer deseo en la inapito, os roles a su hac \n",
            "\n",
            "[1968.0169456005096 (2000 100%) 1.7746]\n",
            "que las\n",
            "mano de la mimo de laciguo y vuestra merced de muscidod, senor de la verrado\n",
            "y aquellos manos  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nbM8qpnOOrX",
        "outputId": "223088e5-7a10-4105-ed4c-aabb898d6157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def show_loss_graph(title, losses):\n",
        "    plt.plot(losses, label=\"Train Loss\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel(\"Avg. Loss per epoch\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylim([0, max(losses)])\n",
        "    plt.xlim([0, len(losses)])\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "show_loss_graph(\"\", all_losses)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee0so6aKJ5L8",
        "outputId": "751b0522-0336-4b93-9f47-9581050a3eeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(15):\n",
        "  start_strings = [\" \", \" Don\", \" él\", \"el\", \" yo \", \" qu\", \" r\", \" la\", \" s\", \" »\", \" >>\", \" ¿\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "#   all_characters.index(string[c])\n",
        "  print(evaluate(start_strings[start], 300), '\\n')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " s\n",
            " se volente el estigar de las que nos encomosiguios palas por las engran de secuderos, que entre la han remegino de ese esto que los mujeros, suemo\n",
            "que hacermo el grande los mundo de don Quijote y en sus ha a vuestra cuando en la cara muchado digo por escardedodas, lo que los megudose dinerandose esta \n",
            "\n",
            "el\n",
            "ella, si estas veces o amentisos de tantos, que me ha#a yo ve cuento a sus mermerampos que no es maneros que evente ingimiento que me la venta, que como por estas pramos en la cuando en esto de casa delante de mis\n",
            "encandases sotrandes y destados las manos en vuastras de camas, y que no Huere tan megur \n",
            "\n",
            " \n",
            " al manera de\n",
            "queria el moro, que no esto que rupies, yo se los hacer que la verdad, sino que, divelew !:lguro de\n",
            "inmestros meder de la encantara, aminados de imagino que el ques, como se quien >un esto, sino quien la cual respondio todo encorrinado, que no que tudo que no esta son de de menos que no \n",
            "\n",
            " ¿\n",
            " ¿amaron que no esto acasar de magre, desperarde de la ella pago mas verced, senoria de la riico a era de esta ?dijo destimiendose al campo doncellaga de un que no los cielan de 0uien vuestra merme tan lo querio de suencio al que se order que dijo! Prezo, el colverode hacer cuenta don Quijote y\n",
            "asi le \n",
            "\n",
            " qu\n",
            " que, el pues, que trate con la suentie de los ojos sando el nueco mi sino cami el cuandeza, se hara de lo cual calando el rostramana de dijo el todo vuestra ganarone de menos,\n",
            "dijo el cuirio que saya de esta de llevados que el eran los otros noches, si muchon moros, y me dices que me la prircio tanto  \n",
            "\n",
            " él\n",
            " élancandose les {arriendo del orrer cuando los quien\n",
            "traen contentos los suidos de las versecas, aunque nrestres\n",
            "composigues de yo que esdo lo verdad la suestra muestra mujer yo la cuento contrata, sino de que hemos, porque hasta madre en la verdad te uno vuestrigo y padre vovos no me pastaros de aque \n",
            "\n",
            " él\n",
            " élcor don Quijote, tengo anmando sus rejes armas, üana\n",
            "yo pote\n",
            "que ha de la ver \"que no ¡saras y puedes, y por la suelas la visto en las orgatos.\n",
            "\n",
            "Con\n",
            "gaso de mazo, no quiere de manogre vuestra puerdad en esta como yo el anremado en comento y asi estuma mejor que todo aÜun estraco en la espada\n",
            "en que  \n",
            "\n",
            " s\n",
            " se condante de lagricion, y asi,, nunca y presander en tan era un licencion que se tuviere yo punto y alguno menostres que no estar tan encanvio cuanto la venturado, que de sela en esta! -respondio don Quijote-, que me hom3 se Úaninasño en la caultavadore por la oque\n",
            "legrio desellar de valance de cui \n",
            "\n",
            " ¿\n",
            " ¿ado que la tiene no ca'a le vostosa- de la vido muchamos y que tanto que trango de los arrados. Y algun deseo de espara? Y, nomo no de lo que esto se vuestra vervedad se la suerte andantes y respondio don Quijote, y\n",
            "aunque estaDas anos se^ contraron que la puede a encamila de la que el que le\n",
            "moneci \n",
            "\n",
            " él\n",
            " élavo parecer la _odos los algunas verguendose en la cuildra y la mio, que dan sermegimiento de su hacer, las Ono orrrio de lo que si entando las merced en\n",
            "estreman merez algun entrario y en como a quien vos las pareces por\n",
            "determentes, alguno he de vuestra merced, se degira de casa persana del guia p \n",
            "\n",
            " qu\n",
            " que le\n",
            "ósgananzo de posiguion y consimento que le escudo en encanto que es uno vaco amorito que puedes os +cistrares de estaPora que es\n",
            "ellos y tantos, porque en mucha las orras, las manos de los alegriguos, continarmelos manos manos se estos de los calsados en mas engrantes a plantadas de los 1imosos \n",
            "\n",
            " ¿\n",
            " ¿enonmelidado que los cuando alvizo casti los discretos, y de las mersenticos, que andantes, se degendimente angentelos agrotos meguerdades de han que quien yo el se traere y todo la pener ~zcho.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CahaDa sesora de vuesto\n",
            "de mal que no\n",
            "como las que la íuicando a vuestra merced ca6a entre tan hal \n",
            "\n",
            " r\n",
            " revido y dierino que me vacaó en camino que esta encemiciones que no de venian, que ellos cuando no\n",
            "lo que sin gana, a las\n",
            "casado una\n",
            "merced por la, sino que no\n",
            "me sin que tengo caÜuelisido, a malos que ha\n",
            "de gran mucha Óunca, a\n",
            "donde esto como\n",
            "en la esperante con suvicen, sino por rico a +rraidar de \n",
            "\n",
            " Don\n",
            " Donge que yo se le mimente que\n",
            "deesamando en mal muestraXF\n",
            "\n",
            "Canto alguno, y que no os venian, de tantos 3nterÜuca aronde las anostros y companias'andose del senores los mios, como\n",
            "me parece redando esta\n",
            "todas que en el otros con esta cristido. Anstrete muchar\n",
            "ellos que no ni (dijo, que vuestra mespada  \n",
            "\n",
            " r\n",
            " respondio que me degante por el janda le dicho la principio de los -real somoto de )que en sus vermente el verviro, romo yo la que, o dendia recato de entre de mono\n",
            "de merced se\n",
            "a camino que le tiento no han de mujer de respondio el ciele en las las palapas de la cual senores de los que lo querio a l \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJhgDc2IauPE"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 6: Generate output on a different dataset\n",
        "\n",
        "---\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "* Choose a textual dataset. Here are some [text datasets](https://www.kaggle.com/datasets?tags=14104-text+data%2C13205-text+mining) from Kaggle \n",
        "\n",
        "* Generate some decent looking results and evaluate your model's performance (say what it did well / not so well)\n",
        "\n",
        "\n",
        "Answer:\n",
        "\n",
        "The model was able to quickly put together that the sequence \"qu\" usually is followed by an \"e\" or \"é\". But the model struggles with figuring out how to use characters with tildes on them. I think my model just wasn't big enough for how many possible characters there were, I had to add a lot of new characters to the list of available characters.\n"
      ]
    }
  ]
}